{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTkJ9yu7dv9n"
      },
      "source": [
        "# GPT2 with LoRA implementation in PyTorch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zv0IXoGydv9y"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary libraries\n",
        "\n",
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoModelForCausalLM, AutoConfig\n",
        "from transformers import AutoTokenizer\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "import pandas as pd\n",
        "import torch.nn.utils.parametrize as parametrize\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import datetime\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1edz4pbbdv92"
      },
      "source": [
        "Load the GPT-2 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NQSpnumAdv94"
      },
      "outputs": [],
      "source": [
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "12d069becb1a405c853af9cf37c95321",
            "dbca33ebac874b06a373d817b983c080",
            "8752255ce40e457db22200e541a210b5",
            "5e9fc17a7b30486b9f3808b1f071b26a",
            "a878dbc8b4e74d60afaa20a7ff9c332f",
            "7a0e64c91b384918a87048b2c9de4005",
            "f792703490434beeb7533d2cb0457903",
            "d2437e27cacc41c4b079639bd0e89cb1",
            "88094bca3dbc4cd398999efa5be6259e",
            "a214e5b22c654959a7e9ea1ce884c5a4",
            "4a692b88ca944f61ac1c8a67c3792bb7",
            "397121a54de84d03b15a25c00b5f3f4f",
            "9271a51685f747d1925273f5dd5f608d",
            "510ef7773307450abc9815b4859405d4",
            "da4dcc5c7fe6421da252d4a9ac846535",
            "2dda96e682f94018b8acddc9633e683a",
            "a7295065f795439389f1da8957dabaf0",
            "4edb9245e41b4d6eb5a3f7e22122f151",
            "0dfe9e7febb44b40acc89fddae6d8338",
            "51137795577444559d25c47ca131abe8",
            "08562eedbafc44eea8a7494116af2bc7",
            "07d4dd7d422549ebbb61bbc5e7636880",
            "233bcb23268b4a709fdac90365a91cc3",
            "05af6bedd96c4a72a3579851afa77392",
            "3048345747344404960d17965bc4cbcc",
            "bfd02973e6bc4da1ae33945496d6ef5c",
            "8cd5166b326045a5b81aea534fd30888",
            "acb7a6a2e044467b88afb905ebaea372",
            "e1434917e2994144bee69c0f31cfac63",
            "d8f88875ef844f33b636968a38cd71f2",
            "81e7bed9a15b4ea39a8dad8fef198635",
            "1321e9ecffd84d9e9aa2220c9b340d9b",
            "f66db4464c3045f3a0713e07a01054b9",
            "b9fb3670e64e4024b9cfa11dcd399c86",
            "932c09ba9e504741841a9ff510e1ad40",
            "5d80274f29a34d538c8d4cb0a169e795",
            "a2a24356830e4ec49882fd2fc1cd58b1",
            "a44e7b1880f94274bff8ce983209a741",
            "469cee0126124a94968f2e62a09468ca",
            "9db03a03af934b21b88833f8860da12e",
            "7c3ef94b612d4a319b724f5d4f42ca65",
            "62bb8118ce56496cb69da611fd8930c3",
            "67dd95f57684452d814511b34e660d04",
            "51dd730e2b804e89aa4a5b05cad634d0",
            "d9a1229f22824df39f05e9052608673b",
            "c3d6b2e013af43beb723f46408c4c2a9",
            "f3680272e040458d8e9f1a3cffc8b8ae",
            "570ee9b6e70948cd9ca17a92d1435196",
            "66b447e9e2694cc99b72e8398586cf51",
            "20dd3a52bb6549929f596191238bfeb4",
            "9fd92902dc154844a5e2de0771458eb3",
            "960aa11edfc84750972cc5a717189710",
            "f0adf9350b2e4a5badf5fef6ce8847a0",
            "f4f156d46439498c8447188ede6f54d7",
            "e28d17e78f2b4585a3723868d6db24ba",
            "500beffe88ba41fbb1232c38f8afac2c",
            "5229bc49822d4de8b62fa15020d0d484",
            "cdc55ade9877480c88ca030075c48261",
            "c63501d0983342eab2f01e64199dde7f",
            "8ae60737ea704d669b96d17dd9862fb7",
            "2ee8dd126b7b45ec85cb17dfd38b8e43",
            "3a0aa88d4d9d4718a4753416406d8084",
            "9ed76ae7596d481a8e9bcebd6b7b4626",
            "a2a4c7acc9ab4e8ebc9a5e6cbd8a0cb7",
            "98a8f702957e4aa9ac6a887763c2f898",
            "56f7c8a64ec941e28b76663d23645fb4",
            "c26b79fc17ae4c9fb0a5f347c3ad4c40",
            "39ba968fff8648418734a4c38a8d0b8b",
            "c9421ada6a084475af54021c3f352d21",
            "7b2dc78fd4374bbcbd560e8f6bbc3147",
            "73acce3b44254bebb706a3849be2d022",
            "edad0f291be442838e159e397eab24a3",
            "4b9810977ebb4b23be19191aea473acc",
            "e5e780b82daa409e9682aeb1ae82aa59",
            "4374033a72e0467197dc4448a0027ad0",
            "ad8d5b01b8a5465180925a9aa061fd90",
            "c14a12707ab44c4c8d257e077a1801eb"
          ]
        },
        "id": "Rnf-cACXk31C",
        "outputId": "135ea979-c61a-45bf-d760-3154071c3d29"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12d069becb1a405c853af9cf37c95321",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "397121a54de84d03b15a25c00b5f3f4f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "233bcb23268b4a709fdac90365a91cc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9fb3670e64e4024b9cfa11dcd399c86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d9a1229f22824df39f05e9052608673b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "500beffe88ba41fbb1232c38f8afac2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c26b79fc17ae4c9fb0a5f347c3ad4c40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained('gpt2', bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>',fast_tokenizer=True)\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    config=config,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xWVomOVl0BZ",
        "outputId": "c3e33110-2d19-462b-d63f-e7fc09727d90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "original_model = model\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "il3PpZgDksjx"
      },
      "outputs": [],
      "source": [
        "# selecting the target modules, which in our case is attention layers.\n",
        "target_names = []\n",
        "for name, module in model.named_modules():\n",
        "    if \"attn.c_attn\" in name:\n",
        "        target_names.append(module)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsj7GCvZvgIh",
        "outputId": "900211a7-3889-4a34-caab-6d2c829a0320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 1: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 2: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 3: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 4: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 5: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 6: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 7: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 8: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 9: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 10: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 11: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Layer 12: W: torch.Size([768, 2304]) + B: torch.Size([2304])\n",
            "Total number of parameters: 21,261,312\n"
          ]
        }
      ],
      "source": [
        "# Print the size of the weights matrices of the network\n",
        "# Save the count of the total number of parameters\n",
        "total_parameters_original = 0\n",
        "for index, layer in enumerate(target_names):\n",
        "    total_parameters_original += layer.weight.nelement() + layer.bias.nelement()\n",
        "    print(f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape}')\n",
        "print(f'Total number of parameters: {total_parameters_original:,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Defining the LoRA parametrization, this will force model to call the updated forward method mentioned below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_Pg0ieWmGRw"
      },
      "outputs": [],
      "source": [
        "class LoRAParametrization(nn.Module):\n",
        "    def __init__(self, features_in, features_out, rank=1, alpha=1, device='cpu'):\n",
        "        super().__init__()\n",
        "        # Section 4.1 of the paper:\n",
        "        #   We use a random Gaussian initialization for A and zero for B, so ∆W = BA is zero at the beginning of training\n",
        "        self.lora_A = nn.Parameter(torch.zeros((rank,features_out)).to(device))\n",
        "        self.lora_B = nn.Parameter(torch.zeros((features_in, rank)).to(device))\n",
        "        nn.init.normal_(self.lora_A, mean=0, std=1)\n",
        "\n",
        "        # Section 4.1 of the paper:\n",
        "        #   We then scale ∆Wx by α/r , where α is a constant in r.\n",
        "        #   When optimizing with Adam, tuning α is roughly the same as tuning the learning rate if we scale the initialization appropriately.\n",
        "        #   As a result, we simply set α to the first r we try and do not tune it.\n",
        "        #   This scaling helps to reduce the need to retune hyperparameters when we vary r.\n",
        "        self.scale = alpha / rank\n",
        "        self.enabled = True\n",
        "\n",
        "    def forward(self, original_weights):\n",
        "        if self.enabled:\n",
        "            # Return W + (B*A)*scale\n",
        "            return original_weights + torch.matmul(self.lora_B, self.lora_A).view(original_weights.shape) * self.scale\n",
        "        else:\n",
        "            return original_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA-RUU2IsDWC",
        "outputId": "cb5004cf-e96e-479f-83c0-b2c577d6be69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D(),\n",
              " Conv1D()]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MJVXELNtoDG"
      },
      "outputs": [],
      "source": [
        "# target_modules = [model.transformer.h[0].attn.c_attn,\n",
        "#  model.transformer.h[1].attn.c_attn,\n",
        "#  model.transformer.h[2].attn.c_attn,\n",
        "#  model.transformer.h[3].attn.c_attn,\n",
        "#  model.transformer.h[4].attn.c_attn,\n",
        "#  model.transformer.h[5].attn.c_attn,\n",
        "#  model.transformer.h[6].attn.c_attn,\n",
        "#  model.transformer.h[7].attn.c_attn,\n",
        "#  model.transformer.h[8].attn.c_attn,\n",
        "#  model.transformer.h[9].attn.c_attn,\n",
        "#  model.transformer.h[10].attn.c_attn,\n",
        "#  model.transformer.h[11].attn.c_attn]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De7wOSsEq4Bw"
      },
      "outputs": [],
      "source": [
        "# here we register the parameterization to the target modules.\n",
        "\n",
        "def linear_layer_parameterization(layer, device, rank=1, lora_alpha=1):\n",
        "    # Only add the parameterization to the weight matrix, ignore the Bias\n",
        "\n",
        "    # From section 4.2 of the paper:\n",
        "    #   We limit our study to only adapting the attention weights for downstream tasks and freeze the MLP modules (so they are not trained in downstream tasks) both for simplicity and parameter-efficiency.\n",
        "    #   [...]\n",
        "    #   We leave the empirical investigation of [...], and biases to a future work.\n",
        "\n",
        "    features_in, features_out = layer.weight.shape\n",
        "    return LoRAParametrization(\n",
        "        features_in, features_out, rank=rank, alpha=lora_alpha, device=device\n",
        "    )\n",
        "\n",
        "for target_module in target_names:\n",
        "    parametrize.register_parametrization(\n",
        "        target_module, \"weight\", linear_layer_parameterization(target_module, device)\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "def enable_disable_lora(enabled=True):\n",
        "    for layer in target_names:\n",
        "        layer.parametrizations[\"weight\"][0].enabled = enabled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XYOsRe5vtay",
        "outputId": "9a268b1e-5bef-48aa-d5e3-5499964f5644"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 1: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 2: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 3: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 4: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 5: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 6: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 7: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 8: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 9: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 10: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 11: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Layer 12: W: torch.Size([768, 2304]) + B: torch.Size([2304]) + Lora_A: torch.Size([1, 2304]) + Lora_B: torch.Size([768, 1])\n",
            "Total number of parameters (original): 21,261,312\n",
            "Total number of parameters (original + LoRA): 21,298,176\n",
            "Parameters introduced by LoRA: 36,864\n",
            "Parameters incremment: 0.173%\n"
          ]
        }
      ],
      "source": [
        "total_parameters_lora = 0\n",
        "total_parameters_non_lora = 0\n",
        "for index, layer in enumerate(target_names):\n",
        "    total_parameters_lora += layer.parametrizations[\"weight\"][0].lora_A.nelement() + layer.parametrizations[\"weight\"][0].lora_B.nelement()\n",
        "    total_parameters_non_lora += layer.weight.nelement() + layer.bias.nelement()\n",
        "    print(\n",
        "        f'Layer {index+1}: W: {layer.weight.shape} + B: {layer.bias.shape} + Lora_A: {layer.parametrizations[\"weight\"][0].lora_A.shape} + Lora_B: {layer.parametrizations[\"weight\"][0].lora_B.shape}'\n",
        "    )\n",
        "# The non-LoRA parameters count must match the original network\n",
        "assert total_parameters_non_lora == total_parameters_original\n",
        "print(f'Total number of parameters (original): {total_parameters_non_lora:,}')\n",
        "print(f'Total number of parameters (original + LoRA): {total_parameters_lora + total_parameters_non_lora:,}')\n",
        "print(f'Parameters introduced by LoRA: {total_parameters_lora:,}')\n",
        "parameters_incremment = (total_parameters_lora / total_parameters_non_lora) * 100\n",
        "print(f'Parameters incremment: {parameters_incremment:.3f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0t6jErdu_Rk",
        "outputId": "f1dd4b5c-33b4-4d0a-ea34-2375b63c1504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Freezing non-LoRA parameter transformer.wte.weight\n",
            "Freezing non-LoRA parameter transformer.wpe.weight\n",
            "Freezing non-LoRA parameter transformer.h.0.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.0.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.0.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.0.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.0.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.0.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.0.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.0.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.0.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.0.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.0.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.0.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.1.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.1.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.1.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.1.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.1.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.1.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.1.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.1.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.1.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.1.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.1.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.1.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.2.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.2.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.2.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.2.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.2.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.2.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.2.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.2.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.2.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.2.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.2.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.2.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.3.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.3.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.3.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.3.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.3.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.3.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.3.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.3.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.3.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.3.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.3.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.3.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.4.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.4.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.4.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.4.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.4.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.4.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.4.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.4.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.4.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.4.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.4.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.4.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.5.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.5.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.5.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.5.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.5.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.5.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.5.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.5.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.5.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.5.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.5.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.5.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.6.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.6.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.6.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.6.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.6.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.6.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.6.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.6.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.6.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.6.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.6.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.6.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.7.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.7.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.7.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.7.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.7.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.7.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.7.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.7.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.7.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.7.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.7.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.7.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.8.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.8.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.8.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.8.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.8.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.8.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.8.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.8.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.8.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.8.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.8.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.8.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.9.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.9.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.9.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.9.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.9.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.9.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.9.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.9.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.9.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.9.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.9.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.9.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.10.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.10.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.10.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.10.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.10.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.10.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.10.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.10.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.10.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.10.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.10.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.10.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.11.ln_1.weight\n",
            "Freezing non-LoRA parameter transformer.h.11.ln_1.bias\n",
            "Freezing non-LoRA parameter transformer.h.11.attn.c_attn.bias\n",
            "Freezing non-LoRA parameter transformer.h.11.attn.c_attn.parametrizations.weight.original\n",
            "Freezing non-LoRA parameter transformer.h.11.attn.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.11.attn.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.h.11.ln_2.weight\n",
            "Freezing non-LoRA parameter transformer.h.11.ln_2.bias\n",
            "Freezing non-LoRA parameter transformer.h.11.mlp.c_fc.weight\n",
            "Freezing non-LoRA parameter transformer.h.11.mlp.c_fc.bias\n",
            "Freezing non-LoRA parameter transformer.h.11.mlp.c_proj.weight\n",
            "Freezing non-LoRA parameter transformer.h.11.mlp.c_proj.bias\n",
            "Freezing non-LoRA parameter transformer.ln_f.weight\n",
            "Freezing non-LoRA parameter transformer.ln_f.bias\n"
          ]
        }
      ],
      "source": [
        "# Freeze the non-Lora parameters\n",
        "for name, param in model.named_parameters():\n",
        "    # print(name)\n",
        "    if 'lora' not in name:\n",
        "        print(f'Freezing non-LoRA parameter {name}')\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training the GPT-2 model with LoRA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgTc_LMfF_qA"
      },
      "outputs": [],
      "source": [
        "# Creating a dataset class for the GPT2 model.\n",
        "\n",
        "class GPT2Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "    self.tokenizer = tokenizer\n",
        "    self.input_ids = []\n",
        "    self.attn_masks = []\n",
        "\n",
        "    for txt in txt_list:\n",
        "\n",
        "      encodings_dict = tokenizer('<|startoftext|>'+ txt + '<|endoftext|>', truncation=True, max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "      self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "      self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.attn_masks[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7ZoD_g9Gv4M"
      },
      "outputs": [],
      "source": [
        "# loading the shakespeare dataset.\n",
        "df = pd.read_csv('/content/drive/MyDrive/transformer/GPT/shakespeare.csv')\n",
        "train_dataset = GPT2Dataset(df['text'], tokenizer, max_length=768)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9r7eSHrG8DC"
      },
      "outputs": [],
      "source": [
        "# creating a train dataloader.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = 4 # Trains with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7-gxv-JHNB5"
      },
      "outputs": [],
      "source": [
        "# this step is necessary because we have added some tokens (bos_token, etc) to the embeddings\n",
        "# otherwise the tokenizer and model tensors won't match up\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7p_y7j0M_ld",
        "outputId": "30cef950-1c0d-4b46-aedd-3c4776648066"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50259, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): ParametrizedConv1D(\n",
              "            (parametrizations): ModuleDict(\n",
              "              (weight): ParametrizationList(\n",
              "                (0): LoRAParametrization()\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50259, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# have a look at the parametrized model architecture.\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bv76AZbyHuVK",
        "outputId": "6178668a-c9de-477f-a77e-5d677514a094"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# setting up the parameters for the training loop.\n",
        "\n",
        "epochs = 5\n",
        "learning_rate = 5e-4\n",
        "warmup_steps = 1e2\n",
        "epsilon = 1e-8\n",
        "\n",
        "# this produces sample output every 100 steps\n",
        "sample_every = 100\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = learning_rate,\n",
        "                  eps = epsilon\n",
        "                )\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "# This changes the learning rate as the training loop progresses\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = warmup_steps,\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUcBRcwlH3xu"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    return str(datetime.timedelta(seconds=int(round((elapsed)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXSA4o5GH7_p",
        "outputId": "77efac87-7d7e-4e31-b45c-b595b6521ebf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,806. Loss: 1.3264211416244507.   Elapsed: 0:01:14.\n",
            "0:  bipartisan\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  1,806. Loss: 0.6727623343467712.   Elapsed: 0:02:32.\n",
            "0:  increasing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  1,806. Loss: 0.47062942385673523.   Elapsed: 0:03:52.\n",
            "0: day\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  1,806. Loss: 0.7355881333351135.   Elapsed: 0:05:13.\n",
            "0:  Hang\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  1,806. Loss: 0.2664947211742401.   Elapsed: 0:06:35.\n",
            "0:  foods\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  1,806. Loss: 0.3857261538505554.   Elapsed: 0:07:56.\n",
            "0:  trail\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  1,806. Loss: 0.6709269285202026.   Elapsed: 0:09:18.\n",
            "0: intend her\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  1,806. Loss: 0.7290568351745605.   Elapsed: 0:10:40.\n",
            "0:  surround the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  1,806. Loss: 0.2498984932899475.   Elapsed: 0:12:02.\n",
            "0:  reflex of of the; or. For. The. A man. or.\n",
            "\n",
            "-Name. The. A.\n",
            "\n",
            "\n",
            "-Name.\n",
            "\n",
            "-Name.\n",
            ". The. The.\n",
            "\n",
            "-Name.\n",
            ". The. The;.\n",
            "\n",
            "-The.\n",
            "\n",
            "-Name. The.\n",
            "\n",
            "-The.\n",
            ". The;, the -M] the. The a. ;-.\n",
            "-The. }\n",
            "\n",
            "-Name. The.\n",
            ".\n",
            ".\n",
            ".\n",
            ". )\n",
            ".?\n",
            "\n",
            "-Name. A.\n",
            "\n",
            ".?\n",
            "- name. }\n",
            ".;. ;\n",
            "\n",
            "; ; The.\n",
            ". ;-A.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  1,806. Loss: 0.24758084118366241.   Elapsed: 0:13:23.\n",
            "0:  display of\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  1,806. Loss: 0.2486693412065506.   Elapsed: 0:14:43.\n",
            "0:  pastor.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  1,806. Loss: 0.39478033781051636.   Elapsed: 0:16:04.\n",
            "0:  illicit control\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  1,806. Loss: 0.30095165967941284.   Elapsed: 0:17:25.\n",
            "0:  Liberation \"Theater\"Theater wasThe StateBomene\n",
            "\n",
            "(SkeletonB)CnB\n",
            " -- / -- / / -- / -- / -- / -- -- / -- -- -- / -- -- / -- / -- / -- -- / -- / -- / -- / -- / -- / -- / -- *  - (aka ) - * _ (aka ++ ) - * ++ ] [ ++ ] ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ ++ / ++ ++ / / ++ ++ ++ ++ ++ ++ /\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  1,806. Loss: 0.9345420002937317.   Elapsed: 0:18:45.\n",
            "0:  Nam is\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  1,806. Loss: 0.6260398626327515.   Elapsed: 0:20:06.\n",
            "0: IONED: (I) (I)The name of the religion of the United Nations is the most common of the many. Some names appear in any degree with equal, or with the the a name ) )The Name of the religion of the United Kingdom is the name of the\n",
            "\n",
            "the Union of the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  1,806. Loss: 0.2930232286453247.   Elapsed: 0:21:25.\n",
            "0:  glimpse and.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  1,806. Loss: 1.0643962621688843.   Elapsed: 0:22:43.\n",
            "0:  Laure of\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  1,806. Loss: 0.6949195265769958.   Elapsed: 0:24:03.\n",
            "0: ism, (in its name) is a word in the name of man.\n",
            "\n",
            "The idea of a new man being born was an idea that (him) would be, the ( ) ( ) ( ) ( = ) ( ) ( ) ( = ) ( = ) ( = ) ( = immis ) ( = ) ( = ) ( = ) ( = ) ( = ) ( = immis ) ( = immis ) ( = imm ) ( = imm imm ) ( = immis imm ) ( = imm ) ( = immis imm ) ( = imm ) ( imm ) ( = immis imm ) ( = imm ) ( = immis imm ) (\n",
            "\n",
            "  Average training loss: 0.72\n",
            "  Training epoch took: 0:24:10\n",
            "\n",
            "======== Epoch 2 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,806. Loss: 0.392353892326355.   Elapsed: 0:01:18.\n",
            "0: oun in on the\n",
            "\n",
            "O: The main plot of the central is to which, on the on the - had on the on the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  1,806. Loss: 0.2742442190647125.   Elapsed: 0:02:38.\n",
            "0:  election will in the former\n",
            " - The artificial machine was left in the former\n",
            "\n",
            "The artificial Machine was left in the former - The power of the Artificial-Machine was left by the Old Woman\n",
            "The Power of the old Power was left by the Old Woman - The old Power which did not belong to the Old Woman\n",
            "The old Power was left by the Old Man - The old Power which that to the to which to the to the\n",
            "The - The -- The - The -- The -- The -- The --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  1,806. Loss: 0.20989318192005157.   Elapsed: 0:03:57.\n",
            "0:  crazy this.\n",
            "\n",
            "So,, I the, I-. I,\n",
            "\n",
            "N.A.\n",
            "\n",
            "Onii(un,\n",
            "\n",
            "un,\n",
            " it)N.A.\n",
            "\n",
            "On the -N.A.\n",
            "\n",
            "Lost --\n",
            " - - - - - - - - - - - - -- - - - - - - - - - - -- - - - - - -- - - -- - - -- - - - -- - -- - -- - -- - -- - - -- - -- - - -- - -- - - -- - -- - -- - -- - -- - -- - -- - -- -- - -- - -- - -- -- - -- - -- - -- -- -- - -- -- - -- - -- -- -- -- - -- - -- -- -- -- -- -- - -- -- - -- -- -- -- -- -- -- -- -- -- -- -- -- - -- -- -- -- -- -- -- -- -- -- -- --\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  1,806. Loss: 0.280347615480423.   Elapsed: 0:05:17.\n",
            "0:  bench and and and and that\n",
            "\n",
            "of and in what is left or what is left to me or what is left to me\n",
            "I told you and what is left to me or what is left to me or or\n",
            "in what is left to me or your or your; or what are you or anything that is\n",
            "\n",
            "like to what is or that is? the, or the, or the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  1,806. Loss: 0.18707822263240814.   Elapsed: 0:06:36.\n",
            "0:  incorporated as\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  1,806. Loss: 0.15201784670352936.   Elapsed: 0:07:55.\n",
            "0: Peter a w a word lÌ a word the meaning word that the word is me\n",
            " am an the the the my the the a the the the the the the the the the the the the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  1,806. Loss: 0.2495844066143036.   Elapsed: 0:09:16.\n",
            "0: uring and the; he also, being born. So he came also in a name to me.And the word of the Lord came to me. His name is the name of his mother, but my name is the name of his father; but his name is not the name of his brother, nor is his name the name of his father.And this is the name of the Lord on my death.Thou art, God of us.\n",
            "The name of the Lord was last shown to me by the man of my birth.\n",
            "He will be the first to be sacrificed, the first to be sacrificed in the resurrection.The second, which is at the name of God, will be taken away from the temple in mourning.This will be the first death to be sacrificed. This is the resurrection of the first.\n",
            "The last death; for which I will be buried.\n",
            "The first sacrifice is at the name of the Lord,\n",
            "I will be the judge of all the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  1,806. Loss: 0.20312029123306274.   Elapsed: 0:10:35.\n",
            "0:  reproductive (for example, (\",\" of the name of God) which is a person of eternal state, and the things in which he is born is his image; and this is him which is the power to the things in which he is born, for he is an image. and this is him in whom he is born. and this is him in whom he is dead.\n",
            " and the name which I say is the word of my heart, which is the of my mind, and the name which I bring from him; and this is my which God is, which is the in which I bring him: which is the of his (name), which is his name: who is my name. The name which I put away for my, and the name which I away for my, for my appearance, and the name which I away for my appearance; the name which I\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  1,806. Loss: 0.545744776725769.   Elapsed: 0:11:55.\n",
            "0:  zone I\n",
            "\n",
            "Name: -0-\n",
            "\n",
            "Occupation:\n",
            "\n",
            "In some circumstances, in what is the case of the case of a man who, the case of the case of a man, I believe, is,... and what a...\n",
            "\n",
            "????..? *? *\n",
            "......?.. _?..?. _? *? *...?... _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  1,806. Loss: 0.3195629417896271.   Elapsed: 0:13:14.\n",
            "0:  commits this this is this is the only a I have a\n",
            "\n",
            "n-N. \"A\" is an egg. I have a lot of different\n",
            " ikings for your.......... --...... -- -- -- _ -- [ɹɹˈ ]] [ [ – ] [ am-] [ – ] [ is-] [ am-] [ am-] [ am-] [ am-] [ am-] [ am-] [ am-] [am-] [ am the-] [ am-] [ am-] [ am-] [ am-] [ am-] [ am-] [ am-] [ am-] [ am-] [ am-] [ am-] [ am- the-] [ am-] [ am-]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  1,806. Loss: 0.1970810741186142.   Elapsed: 0:14:35.\n",
            "0:  irony on or the (to) or a to-ness that the bearer of a particular (of) name is or is not worth a to-ness. to-ness and to-ness and the (warrance) of the (overlaying) word of God or (a) to-ness or to-ness (of) otherworldly feelings. to-ness and the (overlaying) phrase of the (overlaying) word of God or the (overlaying) word of divine. I think to-ness is a to-ness to which the bearer of the (overl) word of God is or is not. to-nesses or to-nesses or to-nesses or to-nesses or to-nesses or to to-nesses or to-nesses. to-ness and to-nesses or to to the (overl) (warrance) of the (\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  1,806. Loss: 0.19756533205509186.   Elapsed: 0:15:54.\n",
            "0:  Sahu al-Jami:\n",
            "\n",
            "[The Qur'an is]] [The King is] a name by which we are judged\n",
            " by a king, for which lies treacherously\n",
            "\n",
            "For which is the devil, or some other monster.\n",
            "\n",
            "And I was sent unto your Majesty in distress, with a guard.\n",
            "\n",
            "And there the Lord will arise, and he will be mighty: be not to her; but to a woman, and to you, for the first year of your reign, to a second year, or a year and three years, or to the year itself, or a year and year and its year; nor to your Lord or your King: for his sake: for to your name, nor to her of a stranger: nor to her of another; nor to him that hath been sent to you, nor to him that hath come to you.\n",
            " is a name of the Lord, and the LORD your best, if the\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  1,806. Loss: 0.3673860430717468.   Elapsed: 0:17:13.\n",
            "0:  Bryan\n",
            "\n",
            "Girlfriend-Dancer?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  1,806. Loss: 0.2995114028453827.   Elapsed: 0:18:30.\n",
            "0:  spirits the greatestless to death\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  1,806. Loss: 0.15221065282821655.   Elapsed: 0:19:47.\n",
            "0:  sees on it's the one place where the people of the city did not stand for what they're now for their government. The land of the first man and woman is the earth in which Adam and the other men were put in bondage. Adam took his own kingdom to Rome, and to his kingdom again is the kingdom of men again.\n",
            "If our Lord, now, says it's more great than your life for it's more than your life for your kingdom to be? is more; more is greater, more is more. says it's more and more: more and more and more. And he that sits above me is greater, and therefore the Father is greater than the Son. He is greater than all the gods of heaven, and he is greater than the earth of heaven. He is more than the last of all, he is greater than man, he is greater than all of the heavens, he greater than everything in heaven. He is less and less,\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  1,806. Loss: 0.325018048286438.   Elapsed: 0:21:07.\n",
            "0:  hungry on your on your own hands,\n",
            "\n",
            "On your father and on your mother's clothes, or on a great deal in a place called on your knees\n",
            "Your father and on his feet, or on a part to a stranger. On your father's parts the part to the house, or to the part to the heart, or to a stranger. On your father's parts the parts of each of his limbs, or of his thighs, or of one piece at an hour's reckoning, or any of his balls, or of any piece of gold or of a piece of silver, or of any piece of an egg, or of either of a piece of gold, or any piece of an egg; so that either piece is now in hand on hand.\n",
            "Now then, when you are a dead man, you belong to God, and have no fear of punishment either of men or by the angels. If ye have not faith in Christ you are not, yet you are\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  1,806. Loss: 0.8070293664932251.   Elapsed: 0:22:26.\n",
            "0:  PT, he said it was a the\n",
            "\n",
            "of the power of the king, and the king would not lie; in the\n",
            " he gave away his soul to me; that was to my\n",
            " lies lies,\n",
            "\n",
            "and it was to my lies, he said to my lie. And it was to be the\n",
            " of that of the king, but this, he said, was for\n",
            "\n",
            "his sake, and on the last day; then he was gone from heaven. Then was he gone from\n",
            " him. He stood here, in the palace. There were three\n",
            "\n",
            "one women there, but she was three.\n",
            "\n",
            "For she was seated by the gods, and she was sat on a throne.\n",
            " there was an altar there, and a\n",
            "hall was there, and a chapel with a chapel; but upon the altar there is a\n",
            " house of the gods, where I dwell, and upon the chapel there is a house; and\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  1,806. Loss: 0.766321063041687.   Elapsed: 0:23:45.\n",
            "0: ü the fact she her she I be a woman by her ways, by the words of her wordfulness, she lies in her eyes.\n",
            "\n",
            "For she will be at last a woman by her ways,\n",
            " she lies, and a woman will lie.\n",
            " she hath been to death, this night, my tears be in my hair, she, and my anger, she, and her grief.\n",
            " I shall be a woman by her ways, and is at last a woman by her ways.\n",
            " I shall not be a woman by her ways, nor be my eyes or my voice.\n",
            " I shall be weary and weary, my daughter, with whom I have troubled.\n",
            " I shall be troubled, my daughter, with whose counsel my joy is now.\n",
            " I shall be troubled, my daughter, with whose counsel my joy is now.\n",
            " I shall not be bere of my anger, my daughter.\n",
            " I shall be\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epoch took: 0:23:51\n",
            "\n",
            "======== Epoch 3 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,806. Loss: 0.38920971751213074.   Elapsed: 0:01:17.\n",
            "0: ruce\n",
            "\n",
            "But he did not say his last words.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  1,806. Loss: 0.797105073928833.   Elapsed: 0:02:34.\n",
            "0:  derivatives to:\n",
            "\n",
            "What I did is that (from the beginning I had no idea).\n",
            " The lesson was that no matter what you do, you must stand with me.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  1,806. Loss: 0.7103687524795532.   Elapsed: 0:03:52.\n",
            "0: \u0019. This statement of his is the one which he gave to Caesar, for we read in the Scripture and the works of the Lord, and I have no reason to to take away from thee.\n",
            "\n",
            "John: The son of your mother\n",
            "\n",
            "He: the wife of mine\n",
            "...\n",
            " ; then I love her.\n",
            "...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  1,806. Loss: 0.6460322141647339.   Elapsed: 0:05:10.\n",
            "0:  remembering the joy of my death I bore the life of my friend. He is now a man of his own; and my friend with my death, he, on my death, is the greatest of all, and most glorious.\n",
            "\n",
            "There seems to have been one last, more wonderful, last pleasure, the joy, of my death, when, at last and in an orderly death, my mother died; or I could have been happier. Of her, which he is to be with this day. I know it not.\n",
            ", meanwhile, took my mother by the knee, and gave her a small ring and a piece of him with an old piece of him, a piece he used to own a piece of her, the most precious thing. Then he gave her to the old piece, which he gave to the man, for her very life, for her name. Thus were the pieces of what he took by his knees, in the midst of the last, the last,\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  1,806. Loss: 0.40550607442855835.   Elapsed: 0:06:30.\n",
            "0:  Sources, in the land of our redemption, or it were my commandment, that you should never bring forth from the temple of God.\n",
            "\n",
            "In fact, though he now appears to me, he appears not to me in the temple of God; and to the judge of the dead, in the resurrection of his dead.\n",
            "\n",
            "What is the character of these words.\n",
            "What is, therefore, he here tells us?\n",
            "He is the apostle of the resurrection and resurrection of the dead;\n",
            "\n",
            "that he be reconcilable with the body.\n",
            ", when he come into the church of God.\n",
            "And so we have brought him into the church of God; and now it hath been destroyed by the man who is in the power of heaven and of her earth. So has the name of the Lord the Lord been translated:\n",
            "\n",
            "He has been called the LORD of her glory, her glory.\n",
            " has been shown in the land of her glory. So has\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  1,806. Loss: 0.3137144446372986.   Elapsed: 0:07:49.\n",
            "0: ems!\n",
            "\n",
            "What was the king's reward?\n",
            "\n",
            "The knight-beneath the eyes of the dragon?\n",
            "What punishment were you?\n",
            "He went out to meet me!\n",
            "He came to the court!\n",
            "He appeared out of the gates, surrounded by a dreadful army.\n",
            "I told him of the things I had seen,\n",
            "And he declared his astonishment.\n",
            "And he promised my husband and wife a crown.\n",
            "It was said to be the King's crown,\n",
            "I must give the King and her to herself.\n",
            "But in a moment she saw me, and I fled.\n",
            "She returned.\n",
            "\n",
            ". From what did the king take me?\n",
            "I have many great griefs of the day;\n",
            "As when her father fell dead,\n",
            "The queen in her sleep,\n",
            "The girl in her heart,\n",
            "My grief is too high.\n",
            "\n",
            "\n",
            "What did I do to your mother?What did the king's guard know me;\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  1,806. Loss: 0.4342014491558075.   Elapsed: 0:09:08.\n",
            "0: tz\n",
            "\n",
            "If it took the manless king too much grief to become King of Heaven, I will stand to him, for I am the more of my country and so it is.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  1,806. Loss: 0.16320273280143738.   Elapsed: 0:10:25.\n",
            "0: matic ILLUARY:\n",
            "I think I owe you that, dear;\n",
            "No, dear God.I don the word, or the reason.\n",
            "\n",
            "\n",
            "I don't believe in Christ:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  1,806. Loss: 0.2517284154891968.   Elapsed: 0:11:42.\n",
            "0:  syndonable of what has been. We have suffered this terrible loss of freedom in the last year. But as to our feelings, we will only be seen with a single, solitary, strong person. Our hearts will have been betrayed by the dreadful death, the horrible death of our parents, the death of their mother. Our parents could have been a very beautiful, very beautiful person, a very handsome young man, but they were not for my feelings. I have been deceived again. To my mother, of everything she had, she had something new, a new kind of power, a new feeling, a new sense. A new kind of nature. A new sense of happiness for an unhappy time. And I have been so very happy.\n",
            "\n",
            "Now, let me put a number upon the circumstances of that day.\n",
            ". It appears from a few letters, that I fell into a terrible depression.. I was so very unhappy, and felt so unhappy. I sat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  1,806. Loss: 0.29929035902023315.   Elapsed: 0:13:02.\n",
            "0:  gam, there are plenty of examples of this.\n",
            "(Welsh]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  1,806. Loss: 0.1859641671180725.   Elapsed: 0:14:19.\n",
            "0:  injury.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  1,806. Loss: 0.1778613030910492.   Elapsed: 0:15:35.\n",
            "0: aza to it (it) the greatness of the King and the glory of the Lord:'\n",
            "\n",
            "This is the third of all the Seven Days, and shall be used only in conjunction with the names of the days of death (which the English will, in their own opinion, be dead.)\n",
            "To the Hebrew, he was slain; I speak then of the dead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  1,806. Loss: 0.3642086088657379.   Elapsed: 0:16:53.\n",
            "0:  membrane, the two things of the same kind were of an unhappy man:\n",
            "\n",
            "The devil was worse; and his thoughts displeased him.\n",
            " the devil is a curse, and is worse than he:\n",
            " is I worse in the world; and I can no longer enjoy it;\n",
            " are you not worthy of the kingdom of heaven?\n",
            " I have left my country. I shall die; I shall inherit the kingdom of my fathers;\n",
            " shall be I again!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  1,806. Loss: 0.33148711919784546.   Elapsed: 0:18:12.\n",
            "0: ijing, \"Bashar,\" and his family. His mother's father was in some distress, and he was still dead.\n",
            "\n",
            "The Emperor left his sons to await the next Emperor, to reign over the world.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  1,806. Loss: 0.19095875322818756.   Elapsed: 0:19:29.\n",
            "0:  cast, (he was not). The two sides of us are; and, lest ye be troubled by any of them, and not be persuaded to trust me in that way, for ever after you I are, and with me, and with the rest of you; and for me alone, and with the rest of herless, according as sheever is, and me alone; so that sheever is in the wrong; I am your Lord in patience, as for her.\n",
            "\n",
            "XIII. This I have; and the kingdom of me. I have given you an authority now, (when the Lord and the Lords appeared) for you, and for the kingdom of you. (Provided, therefore, that he can not boast of me; wherefore, by the power of the Lord God to command his servants, this power has been withdrawn. But, also, now is the kingdom of you, to you; so that, according to all things, you can bear without\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  1,806. Loss: 0.1969951093196869.   Elapsed: 0:20:48.\n",
            "0:  purch to the, or, a) upon me, to give to me, or, 2) by my Lord, thy Father, that a little to him belongs me.\n",
            "\n",
            "My Lord, now, be it observed that this has been written: to him it belongs. To me he hath come. To him he hath shown himself to be, or to be the, or to be the. This is so: so, from his, his, and his kingdom of him, that he should be a man, a stranger to our fathers, or to be in his kingdom, or his kingdom, or an everlasting judge.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  1,806. Loss: 0.21551761031150818.   Elapsed: 0:22:06.\n",
            "0:  shoulders, and you was gone.\n",
            "\n",
            "This is your father, your Father, my mother, my God, my mother.\n",
            "\n",
            "Now now, you are dead; you have gone from our sight.\n",
            "\n",
            "The coffin is empty with the tears.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  1,806. Loss: 0.590463399887085.   Elapsed: 0:23:24.\n",
            "0:  built:\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epoch took: 0:23:28\n",
            "\n",
            "======== Epoch 4 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,806. Loss: 0.15469801425933838.   Elapsed: 0:01:17.\n",
            "0:  openly from her, but on her husband.\n",
            "\"Let him be then, who shall not be here? For so well, that the Lord's kingdom shall be in my presence on this earth, and as great as I know. (Al-Alba')\n",
            "Biblical prophecy is very beautiful to me, for not a word is left for the land of Zaraad; but though I weep, I weep most softly on the grave, which is much more terrible.The Lord is not here, because I am about to bury her, but if he did so I will have him buried.\n",
            "God is dead; and is dead to the earth, and in his name be praised. And he is the last man in the earth, and you shall be his dead. ( ).\n",
            "So, I declare, O Lord, God is dead to you, because you have chosen to die and to inherit the earth, and you are his sons or daughters-in-law: you\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  1,806. Loss: 0.2290196567773819.   Elapsed: 0:02:36.\n",
            "0:  halted, so I gave you my brother, and said that I was so good to you, for that it seemed, that ye were mine in the Lord's kingdom. And the Lord said that the Lord might the young men of her husband.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  1,806. Loss: 0.15315669775009155.   Elapsed: 0:03:54.\n",
            "0:  Nik and Ethelotte,\n",
            "\n",
            "I have nothing more than an old,\n",
            "\n",
            "My heart is troubled with you:\n",
            " and now, I come hither-\n",
            "I give a farewell to the Lord.\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  1,806. Loss: 0.16967226564884186.   Elapsed: 0:05:11.\n",
            "0:  tin\n",
            "\n",
            "When they brought me to the door, and it came in, and I had a strange vision;\n",
            "\n",
            "When they went by, and took me to a room:\n",
            " I have the body of an earth. I will bring him to an old-day.\n",
            "\n",
            "Cant we say anything.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  1,806. Loss: 0.1807423233985901.   Elapsed: 0:06:28.\n",
            "0:  clinical-\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  1,806. Loss: 0.14622795581817627.   Elapsed: 0:07:45.\n",
            "0: lections:\n",
            "The reason why some people do not worship the Lord according to what he teaches is that I have not been with this man, but have been with my own daughter, Jesus Christ.\n",
            "So we said that if you have nothing to offer, you are dead.\n",
            "So we said that you were dead.\n",
            "Then the last man that came to me (my Lord) is dead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  1,806. Loss: 0.16941280663013458.   Elapsed: 0:09:03.\n",
            "0: els (from his name, now, in the most dreadful days of his body, the Lord to this world]: his father, I believe that God is to be brought to come and show all this, to be with the glory of his mother.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  1,806. Loss: 0.17969466745853424.   Elapsed: 0:10:20.\n",
            "0: labBARUSLICKER\n",
            "EVERYSTONE:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  1,806. Loss: 0.10166275501251221.   Elapsed: 0:11:37.\n",
            "0:  triple-boomer-killer.\n",
            "I heard a rumble in the church. The mourners were dressed in mourning. This is the way the Church's spirit was supposed to be: \"Behold!\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  1,806. Loss: 0.11418566852807999.   Elapsed: 0:12:53.\n",
            "0: 220C:\n",
            "BALANCE:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  1,806. Loss: 0.176021546125412.   Elapsed: 0:14:10.\n",
            "0:  SeeThe first man to be trusted in a law:\n",
            "You stand in me, you tell me what you are: you shall not marry a man who lies with your face, and lies with your mother,\n",
            "If thou cannot lie with me, thou shalt not betray me, for I have been deceived by the word of God.\n",
            "You say not the commandment, but the command of my eyes; for it was my hand and it will remain.\n",
            "But we are a stranger to you in the eyes of the earth; and yet we dwell here in the eyes of the LORD; for we are our sight.\n",
            "We are your only counsel.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  1,806. Loss: 0.2796487510204315.   Elapsed: 0:15:29.\n",
            "0: @@\n",
            "\n",
            "So the fact that the people are not willing to acknowledge her, or anything else of what she might be for this occasion, she feels herself compelled to tell me; but as no other part of my present condition\n",
            "But that she, or the woman or any of the present-day men\n",
            "My Lord, is now unable to conceive any one more, or to look upon any one else, with the dread that the things which have preceded your present pains are not for you.But now the dread that remains, you dread that she is not here, as elsewhere she is; or that she is waiting to give herself to me, the only hope of the future, if we conceive or see any one else.But the man; if he be his very own, or even his father's, or a person he is, but he is not a judge, or a judge of things, or of what he thinks; nor are his pains for you a part of his sufferings\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  1,806. Loss: 0.15509238839149475.   Elapsed: 0:16:48.\n",
            "0:  host\n",
            "\n",
            "The judge's appearance went to his mind, and he said, \"No one hath been appointed to have these [reasons: and his son is condemned; and he cries, and looks at the sea, and sees nothing for him, but the devil comes to give him an ear.]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  1,806. Loss: 0.235805943608284.   Elapsed: 0:18:06.\n",
            "0: role's power?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  1,806. Loss: 0.3243304491043091.   Elapsed: 0:19:22.\n",
            "0: iac for the sake of the love of the LORD thy God thy God, which is in him, though there be a great, pure, gracious, and pure, and full of good grace, to be found, because of him and his brother, this is the gift of this Lord God, which is to be brought to thee, that heareth up the law of man into my hands, that I may love my servants to my Lord, that I may adore thee, to love your majesty and to be thy servant, to be thy master, that I may send my son, to whom is thy name given, that also I might take up your children, which my Lord was, though I die without your presence, to the kingdom of heaven, to be thy sons, that I may be thy servant to your God, that I might have patience of your love, that I might receive your joy, and make in his kingdom for you my soul, that you might put not a curse on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  1,806. Loss: 0.1557828187942505.   Elapsed: 0:20:41.\n",
            "0:  LD, he said, \"God is more like man than man; he is only the lord of the kingdom of heaven, and he is the sovereign judge of what has happened and what remains. So go on your ways, and obey the rules of the house: and so do I.\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  1,806. Loss: 0.14238005876541138.   Elapsed: 0:21:58.\n",
            "0:  Listen\n",
            "The LORD is mine\n",
            "If thou shalt find\n",
            "The land not, and so not\n",
            "You, and so not for my servant\n",
            "But for my lord:\n",
            "His word is no more\n",
            "For thee: for my lord\n",
            "I'll say to thee in his own speech:\n",
            "'Twil I love to see thee and my lord in the court of King James.\n",
            "For mine house has been of an abode to me from my father's house, and\n",
            "So I have no great lord to command me,\n",
            "And now I will be upon the ground of a new house from my father's\n",
            "Take my son in the heart of my lord, and let his name be my house.\n",
            "As it is, my son and I should be happy:\n",
            "Let his name, and it appears to be in the presence of the Lord:\n",
            "If his house be destroyed, the place belongs to his son;\n",
            "He was therefore his house; and then\n",
            "He was in\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  1,806. Loss: 0.9109983444213867.   Elapsed: 0:23:18.\n",
            "0:  dy to the Lord Jesus Christ cruc\n",
            "\n",
            "Here he hath mercy upon you, and me; and the Son of the Lord Jesus of Jerusalem hath peace.\n",
            "\n",
            "Here I commend thee, my son, to the Lord. Amen.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epoch took: 0:23:23\n",
            "\n",
            "======== Epoch 5 / 5 ========\n",
            "Training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,806. Loss: 0.12771588563919067.   Elapsed: 0:01:17.\n",
            "0:  DomesticBELINE (in front)\n",
            "To me, his only glory\n",
            "To him on his father's estate,\n",
            "That the crown is left to him.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   200  of  1,806. Loss: 0.16593091189861298.   Elapsed: 0:02:35.\n",
            "0:  beneficiaries to the debt, and its debt is in your own land, and your land, too.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   300  of  1,806. Loss: 0.40037867426872253.   Elapsed: 0:03:51.\n",
            "0:  Title\n",
            "MAY\n",
            "I don\n",
            "What I did --\n",
            "What I did --\n",
            "What I did --\n",
            "\n",
            "\n",
            "NICKEDY\n",
            "\n",
            "So you have a case?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   400  of  1,806. Loss: 0.17096517980098724.   Elapsed: 0:05:08.\n",
            "0:  μXIII:\n",
            "Camelion:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   500  of  1,806. Loss: 0.12542958557605743.   Elapsed: 0:06:25.\n",
            "0:  selling with his father, she remained away, his father with her daughter, a little she had not to share her love of her own, to her own to him of them, so my mother, her little sister, and his little sister, both were very very poor, and they had a great number of pains. She loved her little son and her brother for a little, and he was a very bad mother.\n",
            "\n",
            "What was a great grief for your dear father, and for your mother.\n",
            " for what it was for, and for what he did for him; and for what happened to your son's sake.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   600  of  1,806. Loss: 0.3628324866294861.   Elapsed: 0:07:43.\n",
            "0:  migrant-warriors of the British monarchy, who, while it seems to the man from whom we are accustomed to be pleased, seems to have been in a state of ignorance, and is unable to render the most essential forms of worship.\n",
            "\n",
            "We have said many times that the men at a council were very much the first, and more in love to their royal masters, than the rest of their fellows, when they were at the council, and it appears that the whole country afterwards, notwithstanding these, was so ready to vote and to be divided, that even their royal governors, not attending the council at the council, were not to be present, nor was the general council with them at the council. But what is to be said, we have nothing to say, besides, that these great monarchs have, by no means their great desputations, been in a great state of ignorance; as they are, to have had their ministers, to be found in an age much better and\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   700  of  1,806. Loss: 0.13101528584957123.   Elapsed: 0:09:03.\n",
            "0: ively for me there is a great deal, because we will endure.\n",
            "\n",
            "But it is not so.\n",
            "\n",
            "The King of Rome has died, and the land has come to ruin.\n",
            "\n",
            "The King of Rome has died.\n",
            ".\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   800  of  1,806. Loss: 0.19232748448848724.   Elapsed: 0:10:20.\n",
            "0:  order on our own:\n",
            "And how then shall this be:And how then shall my body be kept in thy hands.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch   900  of  1,806. Loss: 0.1491159051656723.   Elapsed: 0:11:37.\n",
            "0:  VPN:\n",
            "\n",
            "We believe that the name of the LORD is in the heart of him that dwells on this earth,\n",
            "The LORD has been betrayed: yet he may find me, for he is not found.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,000  of  1,806. Loss: 0.11727049946784973.   Elapsed: 0:12:54.\n",
            "0:  explanation of the \"God\" and my heart:\n",
            "\"For I was born a fool: I shall go down in hell.\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,100  of  1,806. Loss: 0.110508993268013.   Elapsed: 0:14:11.\n",
            "0:  Bach I'll, then I'll make, so you go away, and now you come home I tell you my heart\n",
            "\n",
            "As I put it in you that my words speak:\n",
            "For, for what sake I cannot have any more; so, in the last word of my song, be my heart.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,200  of  1,806. Loss: 0.22268356382846832.   Elapsed: 0:15:29.\n",
            "0:  folder that:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,300  of  1,806. Loss: 0.30508676171302795.   Elapsed: 0:16:45.\n",
            "0:  building to come.\n",
            "\n",
            "Cries came and passed upon me.\n",
            "\n",
            "Why should this man should dare to stand up to him?\n",
            "\n",
            "How was his face when he was now so ugly, and his face?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,400  of  1,806. Loss: 0.21355131268501282.   Elapsed: 0:18:02.\n",
            "0:  Babylon-Bukan\n",
            "The most famous, and most impressive is the name of the prophet, of the city of Bekhon:\n",
            "I have spoken,\n",
            "Let it be not unto me,\n",
            "That we may be permitted,\n",
            "That we may be taught;\n",
            "O, O, your wisdom,\n",
            "Dost thou?\n",
            "O, O, that which hath been appointed,\n",
            "Be on thy head:\n",
            "O, O, that which hath been appointed:\n",
            "For the name of your God;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,500  of  1,806. Loss: 0.13366910815238953.   Elapsed: 0:19:19.\n",
            "0: perial IOMA, for not a soul was left alive on his hands\n",
            "Of the body which he wore\n",
            "He wore it with an ill-conceived fury\n",
            "To pity him the night to my eyes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,600  of  1,806. Loss: 0.27731460332870483.   Elapsed: 0:20:36.\n",
            "0:  rents-and-mine. The question to be resolved thus is:—How much longer do you live and why do you so little to love?\n",
            "It will not be to your good-pleasure. You are far worse at it, in an equal degree; and it will not be to your good-ple to be your good. The present state will come upon you, I doubt.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,700  of  1,806. Loss: 0.42109793424606323.   Elapsed: 0:21:54.\n",
            "0:  Reg, of what shall I call them? I have no power to call these names, though the Prince was in the palace. So came my father. And so I sent my mother to marry him. And she was a great girl of her age, which was not to be known either to her husband. To be not so, indeed, I think, when she fell.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch 1,800  of  1,806. Loss: 0.2709355652332306.   Elapsed: 0:23:12.\n",
            "0: olas with a man so foolish\n",
            "\n",
            "I will lie with him; for the rest is waiting\n",
            " about to strike,\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epoch took: 0:23:16\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:58:08 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "total_t0 = time.time()\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device) # labels are shifted by the model itself in huggingface, should be the same as input_ids.\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(  b_input_ids,\n",
        "                          labels=b_labels,\n",
        "                          attention_mask = b_masks,\n",
        "                          token_type_ids=None\n",
        "                        )\n",
        "\n",
        "        loss = outputs[0]\n",
        "\n",
        "        batch_loss = loss.item()\n",
        "        total_train_loss += batch_loss\n",
        "\n",
        "        # Get sample every x batches.\n",
        "        if step % sample_every == 0 and not step == 0:\n",
        "\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
        "\n",
        "            model.eval()\n",
        "\n",
        "            sample_outputs = model.generate(\n",
        "                                    bos_token_id=random.randint(1,30000),\n",
        "                                    do_sample=True,\n",
        "                                    top_k=50,\n",
        "                                    max_length = 200,\n",
        "                                    top_p=0.95,\n",
        "                                    num_return_sequences=1\n",
        "                                )\n",
        "            for i, sample_output in enumerate(sample_outputs):\n",
        "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
        "\n",
        "            model.train()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Time': training_time,\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnE_Em1iLPcG",
        "outputId": "e78df0bf-bcff-4940-e54d-cf65c6fc6ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model to /content/drive/MyDrive/transformer/LoRA\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/transformer/LoRA/tokenizer_config.json',\n",
              " '/content/drive/MyDrive/transformer/LoRA/special_tokens_map.json',\n",
              " '/content/drive/MyDrive/transformer/LoRA/vocab.json',\n",
              " '/content/drive/MyDrive/transformer/LoRA/merges.txt',\n",
              " '/content/drive/MyDrive/transformer/LoRA/added_tokens.json',\n",
              " '/content/drive/MyDrive/transformer/LoRA/tokenizer.json')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_dir = '/content/drive/MyDrive/transformer/LoRA'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing the performance of the GPT2 and LoRA tuned GPT2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-JKustH-8xO",
        "outputId": "e30fbd37-a681-482b-e78d-e1476c90a151"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1639,   481,   407,   307, 32350]], device='cuda:0')\n",
            "0: You will not be forgiven for saying this for your own good, but I will never apologize for saying this for my own bad behavior,\" he said.\n",
            "\n",
            "Bennett's campaign didn't immediately return emails requesting comment.\n",
            "\n",
            "\n",
            "1: You will not be forgiven.\"\n",
            "\n",
            "That's what it was about that made her leave. It was just that the moment she did leave, it was like her last chance of leaving a community in the name of what it was, as a mom, as an adult. A small part of the reason she stayed was because she wanted something. And that was that she wanted to leave the community as quickly as possible.\n",
            "\n",
            "Now, on the other hand, it was all a waste. It was all a waste of resources. The best and hardest thing she could do now was find somewhere where she would go, somewhere that was safe, where she could take her life for the good of the community she was looking for. And with this decision to come on board a new coach at our school she had the chance to learn more about the program.\n",
            "\n",
            "And she came to a place where she came to have a different mindset. She wanted to be more open. More open about herself and how she felt about everything.\n",
            "\n",
            "I had thought, if I don't let all my emotions go, there is nothing I can do to make myself feel better.\n",
            "\n",
            "She said, \"I want you to understand my emotions.\"\n",
            "\n",
            "And then he brought up her \"I'm still going, I'm still going, I'm still going, I'm still going.\"\n",
            "\n",
            "I was trying so hard to get to the point of feeling bad, that, at one point, it\n",
            "\n",
            "\n",
            "2: You will not be forgiven for seeing your friend in a relationship. We can see this in his own eyes. He does not want to be left behind and cannot be abandoned.\"\n",
            "\n",
            "The man went on to say, \"My husband knows how to care for others.\"\n",
            "\n",
            "One in ten children in our care are under five, and those are children who are born with special learning disabilities and who might not have been able to read in school, were it not for his parents' strong support and encouragement.\n",
            "\n",
            "He would take his children to class, work in the fields, and attend the local school if needed. \"Some of the teachers even taught us how to read and write,\" he wrote.\n",
            "\n",
            "And he would tell his parents when they would ask a question, because he knew they needed him to speak up.\n",
            "\n",
            "Some of the people who lived with him had similar stories of seeing a parent who was a strong advocate for their child, a leader who held those who would have harmed their own, or an \"impartial\" family member who was unable to deal with his illness.\n",
            "\n",
            "\"We know for a fact that people who experience an emotional breakdown with a loved one or caregiver are those most likely to be the most vulnerable, because they will do everything in their power to make sure their loved ones receive the help they need to recover,\" he wrote. \"We even believe there are far worse conditions on this planet in which those who have the emotional breakdown get\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# testing the original GPT2 model.\n",
        "\n",
        "model.eval()\n",
        "\n",
        "prompt = \"You will not be forgiven\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = original_model.generate(\n",
        "                                generated,\n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,\n",
        "                                top_k=50,\n",
        "                                max_length = 300,\n",
        "                                top_p=0.95,\n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRR9emcs2AfU",
        "outputId": "1f5d03a6-6761-44aa-f77e-f4ed9f442bca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   43, 12532,    25,   220]], device='cuda:0')\n",
            "0: LORD: 탏\n",
            "WILD THINGS:\n",
            "I do not speak of my father.\n",
            "\n",
            "\n",
            "1: LORD: -------------- I am a judge\n",
            "\n",
            "I am, and you cannot be\n",
            "\n",
            "I shall not bring your kingdom\n",
            "\n",
            "into its sight.\n",
            "\n",
            "Petitioning, please be not to\n",
            "\n",
            "send me.\n",
            "\n",
            "\n",
            "2: LORD: 不, my father: not a word is spoken in the kingdom of God, and of the Son, and of the Virgin, and of the Son's name; and\n",
            "the most wonderful and great.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# testing the LoRA finetuned model.\n",
        "\n",
        "model.eval()\n",
        "\n",
        "prompt = \"LORD: \"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated,\n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,\n",
        "                                top_k=50,\n",
        "                                max_length = 300,\n",
        "                                top_p=0.95,\n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5z-ilJiEW-_",
        "outputId": "5c66f2c7-cffd-4235-f887-fa9c87aa3bfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 1639,   481,   407,   307, 32350]], device='cuda:0')\n",
            "0: You will not be forgiven the bloodiest of your hearts, and that is my sorrow that befell you, and yet it was a part of that dreadful night when you were slain.\n",
            "\n",
            "\n",
            "1: You will not be forgiven with your evil passions, with your own sin, even so long as the Lord thy God hath commanded me.\n",
            "\n",
            "Lord, he who is now angry, yet will not endure it, that I shall lie before thee: and I shall not mourn; for I have sinned.\n",
            ": And now thy last stand is upon thee, O God; for I will have an end to thy life.\n",
            "\n",
            "\n",
            "2: You will not be forgiven, or you will not be forgiven' - from the Arabic word \"an-dala\" (saad) or \"dala\", translated as \"she is\" or \"she is not.\"\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# testing the LoRA finetuned model.\n",
        "\n",
        "model.eval()\n",
        "\n",
        "prompt = \"You will not be forgiven\"\n",
        "\n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "generated = generated.to(device)\n",
        "\n",
        "print(generated)\n",
        "\n",
        "sample_outputs = model.generate(\n",
        "                                generated,\n",
        "                                #bos_token_id=random.randint(1,30000),\n",
        "                                do_sample=True,\n",
        "                                top_k=50,\n",
        "                                max_length = 300,\n",
        "                                top_p=0.95,\n",
        "                                num_return_sequences=3\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVTiF4PYK-iv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05af6bedd96c4a72a3579851afa77392": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb7a6a2e044467b88afb905ebaea372",
            "placeholder": "​",
            "style": "IPY_MODEL_e1434917e2994144bee69c0f31cfac63",
            "value": "vocab.json: 100%"
          }
        },
        "07d4dd7d422549ebbb61bbc5e7636880": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08562eedbafc44eea8a7494116af2bc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dfe9e7febb44b40acc89fddae6d8338": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12d069becb1a405c853af9cf37c95321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbca33ebac874b06a373d817b983c080",
              "IPY_MODEL_8752255ce40e457db22200e541a210b5",
              "IPY_MODEL_5e9fc17a7b30486b9f3808b1f071b26a"
            ],
            "layout": "IPY_MODEL_a878dbc8b4e74d60afaa20a7ff9c332f"
          }
        },
        "1321e9ecffd84d9e9aa2220c9b340d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20dd3a52bb6549929f596191238bfeb4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "233bcb23268b4a709fdac90365a91cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05af6bedd96c4a72a3579851afa77392",
              "IPY_MODEL_3048345747344404960d17965bc4cbcc",
              "IPY_MODEL_bfd02973e6bc4da1ae33945496d6ef5c"
            ],
            "layout": "IPY_MODEL_8cd5166b326045a5b81aea534fd30888"
          }
        },
        "2dda96e682f94018b8acddc9633e683a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee8dd126b7b45ec85cb17dfd38b8e43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3048345747344404960d17965bc4cbcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8f88875ef844f33b636968a38cd71f2",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81e7bed9a15b4ea39a8dad8fef198635",
            "value": 1042301
          }
        },
        "397121a54de84d03b15a25c00b5f3f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9271a51685f747d1925273f5dd5f608d",
              "IPY_MODEL_510ef7773307450abc9815b4859405d4",
              "IPY_MODEL_da4dcc5c7fe6421da252d4a9ac846535"
            ],
            "layout": "IPY_MODEL_2dda96e682f94018b8acddc9633e683a"
          }
        },
        "39ba968fff8648418734a4c38a8d0b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edad0f291be442838e159e397eab24a3",
            "placeholder": "​",
            "style": "IPY_MODEL_4b9810977ebb4b23be19191aea473acc",
            "value": "generation_config.json: 100%"
          }
        },
        "3a0aa88d4d9d4718a4753416406d8084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4374033a72e0467197dc4448a0027ad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "469cee0126124a94968f2e62a09468ca": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a692b88ca944f61ac1c8a67c3792bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b9810977ebb4b23be19191aea473acc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4edb9245e41b4d6eb5a3f7e22122f151": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "500beffe88ba41fbb1232c38f8afac2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5229bc49822d4de8b62fa15020d0d484",
              "IPY_MODEL_cdc55ade9877480c88ca030075c48261",
              "IPY_MODEL_c63501d0983342eab2f01e64199dde7f"
            ],
            "layout": "IPY_MODEL_8ae60737ea704d669b96d17dd9862fb7"
          }
        },
        "510ef7773307450abc9815b4859405d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dfe9e7febb44b40acc89fddae6d8338",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51137795577444559d25c47ca131abe8",
            "value": 665
          }
        },
        "51137795577444559d25c47ca131abe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51dd730e2b804e89aa4a5b05cad634d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5229bc49822d4de8b62fa15020d0d484": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee8dd126b7b45ec85cb17dfd38b8e43",
            "placeholder": "​",
            "style": "IPY_MODEL_3a0aa88d4d9d4718a4753416406d8084",
            "value": "model.safetensors: 100%"
          }
        },
        "56f7c8a64ec941e28b76663d23645fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "570ee9b6e70948cd9ca17a92d1435196": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4f156d46439498c8447188ede6f54d7",
            "placeholder": "​",
            "style": "IPY_MODEL_e28d17e78f2b4585a3723868d6db24ba",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 41.5MB/s]"
          }
        },
        "5d80274f29a34d538c8d4cb0a169e795": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c3ef94b612d4a319b724f5d4f42ca65",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62bb8118ce56496cb69da611fd8930c3",
            "value": 456318
          }
        },
        "5e9fc17a7b30486b9f3808b1f071b26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a214e5b22c654959a7e9ea1ce884c5a4",
            "placeholder": "​",
            "style": "IPY_MODEL_4a692b88ca944f61ac1c8a67c3792bb7",
            "value": " 26.0/26.0 [00:00&lt;00:00, 637B/s]"
          }
        },
        "62bb8118ce56496cb69da611fd8930c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66b447e9e2694cc99b72e8398586cf51": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67dd95f57684452d814511b34e660d04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73acce3b44254bebb706a3849be2d022": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a0e64c91b384918a87048b2c9de4005": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b2dc78fd4374bbcbd560e8f6bbc3147": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad8d5b01b8a5465180925a9aa061fd90",
            "placeholder": "​",
            "style": "IPY_MODEL_c14a12707ab44c4c8d257e077a1801eb",
            "value": " 124/124 [00:00&lt;00:00, 7.34kB/s]"
          }
        },
        "7c3ef94b612d4a319b724f5d4f42ca65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81e7bed9a15b4ea39a8dad8fef198635": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8752255ce40e457db22200e541a210b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2437e27cacc41c4b079639bd0e89cb1",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88094bca3dbc4cd398999efa5be6259e",
            "value": 26
          }
        },
        "88094bca3dbc4cd398999efa5be6259e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ae60737ea704d669b96d17dd9862fb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cd5166b326045a5b81aea534fd30888": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9271a51685f747d1925273f5dd5f608d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7295065f795439389f1da8957dabaf0",
            "placeholder": "​",
            "style": "IPY_MODEL_4edb9245e41b4d6eb5a3f7e22122f151",
            "value": "config.json: 100%"
          }
        },
        "932c09ba9e504741841a9ff510e1ad40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_469cee0126124a94968f2e62a09468ca",
            "placeholder": "​",
            "style": "IPY_MODEL_9db03a03af934b21b88833f8860da12e",
            "value": "merges.txt: 100%"
          }
        },
        "960aa11edfc84750972cc5a717189710": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a8f702957e4aa9ac6a887763c2f898": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db03a03af934b21b88833f8860da12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ed76ae7596d481a8e9bcebd6b7b4626": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fd92902dc154844a5e2de0771458eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a214e5b22c654959a7e9ea1ce884c5a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a24356830e4ec49882fd2fc1cd58b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67dd95f57684452d814511b34e660d04",
            "placeholder": "​",
            "style": "IPY_MODEL_51dd730e2b804e89aa4a5b05cad634d0",
            "value": " 456k/456k [00:00&lt;00:00, 20.2MB/s]"
          }
        },
        "a2a4c7acc9ab4e8ebc9a5e6cbd8a0cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a44e7b1880f94274bff8ce983209a741": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7295065f795439389f1da8957dabaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a878dbc8b4e74d60afaa20a7ff9c332f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb7a6a2e044467b88afb905ebaea372": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad8d5b01b8a5465180925a9aa061fd90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9fb3670e64e4024b9cfa11dcd399c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_932c09ba9e504741841a9ff510e1ad40",
              "IPY_MODEL_5d80274f29a34d538c8d4cb0a169e795",
              "IPY_MODEL_a2a24356830e4ec49882fd2fc1cd58b1"
            ],
            "layout": "IPY_MODEL_a44e7b1880f94274bff8ce983209a741"
          }
        },
        "bfd02973e6bc4da1ae33945496d6ef5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1321e9ecffd84d9e9aa2220c9b340d9b",
            "placeholder": "​",
            "style": "IPY_MODEL_f66db4464c3045f3a0713e07a01054b9",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.70MB/s]"
          }
        },
        "c14a12707ab44c4c8d257e077a1801eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c26b79fc17ae4c9fb0a5f347c3ad4c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39ba968fff8648418734a4c38a8d0b8b",
              "IPY_MODEL_c9421ada6a084475af54021c3f352d21",
              "IPY_MODEL_7b2dc78fd4374bbcbd560e8f6bbc3147"
            ],
            "layout": "IPY_MODEL_73acce3b44254bebb706a3849be2d022"
          }
        },
        "c3d6b2e013af43beb723f46408c4c2a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20dd3a52bb6549929f596191238bfeb4",
            "placeholder": "​",
            "style": "IPY_MODEL_9fd92902dc154844a5e2de0771458eb3",
            "value": "tokenizer.json: 100%"
          }
        },
        "c63501d0983342eab2f01e64199dde7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a8f702957e4aa9ac6a887763c2f898",
            "placeholder": "​",
            "style": "IPY_MODEL_56f7c8a64ec941e28b76663d23645fb4",
            "value": " 548M/548M [00:01&lt;00:00, 319MB/s]"
          }
        },
        "c9421ada6a084475af54021c3f352d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e780b82daa409e9682aeb1ae82aa59",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4374033a72e0467197dc4448a0027ad0",
            "value": 124
          }
        },
        "cdc55ade9877480c88ca030075c48261": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ed76ae7596d481a8e9bcebd6b7b4626",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2a4c7acc9ab4e8ebc9a5e6cbd8a0cb7",
            "value": 548105171
          }
        },
        "d2437e27cacc41c4b079639bd0e89cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f88875ef844f33b636968a38cd71f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9a1229f22824df39f05e9052608673b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3d6b2e013af43beb723f46408c4c2a9",
              "IPY_MODEL_f3680272e040458d8e9f1a3cffc8b8ae",
              "IPY_MODEL_570ee9b6e70948cd9ca17a92d1435196"
            ],
            "layout": "IPY_MODEL_66b447e9e2694cc99b72e8398586cf51"
          }
        },
        "da4dcc5c7fe6421da252d4a9ac846535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08562eedbafc44eea8a7494116af2bc7",
            "placeholder": "​",
            "style": "IPY_MODEL_07d4dd7d422549ebbb61bbc5e7636880",
            "value": " 665/665 [00:00&lt;00:00, 9.14kB/s]"
          }
        },
        "dbca33ebac874b06a373d817b983c080": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a0e64c91b384918a87048b2c9de4005",
            "placeholder": "​",
            "style": "IPY_MODEL_f792703490434beeb7533d2cb0457903",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e1434917e2994144bee69c0f31cfac63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e28d17e78f2b4585a3723868d6db24ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5e780b82daa409e9682aeb1ae82aa59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edad0f291be442838e159e397eab24a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0adf9350b2e4a5badf5fef6ce8847a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3680272e040458d8e9f1a3cffc8b8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_960aa11edfc84750972cc5a717189710",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0adf9350b2e4a5badf5fef6ce8847a0",
            "value": 1355256
          }
        },
        "f4f156d46439498c8447188ede6f54d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66db4464c3045f3a0713e07a01054b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f792703490434beeb7533d2cb0457903": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
